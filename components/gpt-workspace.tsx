"use client";

import { useState, useEffect, useRef } from "react";
import { Card } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";
import { Badge } from "@/components/ui/badge";
import {
  Send,
  Bot,
  User,
  Loader2,
  AlertCircle,
  Zap,
  Users,
  Clock,
  CheckCircle2,
} from "lucide-react";
import { toast } from "sonner";
import { Progress } from "@/components/ui/progress";
import { useLanguage } from "@/components/language-provider";
import { useTranslations } from "@/lib/i18n";
import { getClientAuthToken } from "@/lib/client-auth";
import { useWorkspaceMessages } from "@/components/workspace-messages-context";
import { ChatToolbar } from "@/components/chat-toolbar";
import { MarkdownRenderer } from "@/components/markdown-renderer";

interface AIResponse {
  agentId: string;
  agentName: string;
  content: string;
  tokens?: number;
  cost?: number;
  status: "pending" | "processing" | "completed" | "error";
  timestamp: Date;
}

interface Message {
  id: string;
  role: "user" | "assistant";
  content: string | AIResponse[];
  isMultiAI?: boolean;
  timestamp: Date;
}

interface AIAgent {
  id: string;
  name: string;
  provider: string;
  model: string;
  description: string;
  capabilities: string[];
  maxTokens?: number;
  temperature?: number;
  icon?: string;
}

interface GPTWorkspaceProps {
  selectedGPTs: AIAgent[];
  setSelectedGPTs: (gpts: AIAgent[]) => void;
  availableAIs: AIAgent[];
}

export function GPTWorkspace({
  selectedGPTs,
  setSelectedGPTs,
  availableAIs,
}: GPTWorkspaceProps) {
  const [input, setInput] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [aiResponses, setAIResponses] = useState<AIResponse[]>([]);
  const [shouldAutoScroll, setShouldAutoScroll] = useState(true);
  const [sessionConfig, setSessionConfig] = useState<any>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const chatContainerRef = useRef<HTMLDivElement>(null);
  const { language } = useLanguage();
  const t = useTranslations(language);

  // ä½¿ç”¨å…¨å±€ Context ç®¡ç†æ¶ˆæ¯å’Œä¼šè¯ ID
  const {
    messages,
    setMessages,
    addMessage,
    currentSessionId,
    setCurrentSessionId,
    clearMessages,
  } = useWorkspaceMessages();

  // æ£€æµ‹ç”¨æˆ·æ˜¯å¦æ‰‹åŠ¨å‘ä¸Šæ»šåŠ¨
  const handleChatScroll = (e: React.UIEvent<HTMLDivElement>) => {
    const element = e.currentTarget;
    const isNearBottom = element.scrollHeight - element.scrollTop - element.clientHeight < 100;
    setShouldAutoScroll(isNearBottom);
  };

  // åœ¨æ¶ˆæ¯æˆ– AI å›å¤æ›´æ–°æ—¶æ»šåŠ¨åˆ°åº•éƒ¨ï¼ˆå¦‚æœç”¨æˆ·æœªæ‰‹åŠ¨å‘ä¸Šæ»šåŠ¨ï¼‰
  useEffect(() => {
    if (shouldAutoScroll) {
      messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
    }
  }, [messages, aiResponses, shouldAutoScroll]);

  // å½“ä¼šè¯IDæ”¹å˜æ—¶ï¼Œä»æ•°æ®åº“åŠ è½½å†å²æ¶ˆæ¯
  useEffect(() => {
    const loadMessagesFromDatabase = async () => {
      if (!currentSessionId) return;

      try {
        const { token } = await getClientAuthToken();
        if (!token) return;

        const response = await fetch(
          `/api/chat/sessions/${currentSessionId}/messages`,
          {
            headers: {
              Authorization: `Bearer ${token}`,
              "Content-Type": "application/json",
            },
          }
        );

        if (!response.ok) {
          console.error("Failed to load messages:", response.status);
          return;
        }

        const data = await response.json();
        const loadedMessages = data.messages || [];
        const loadedSessionConfig = data.sessionConfig || null;

        // è½¬æ¢æ•°æ®åº“æ¶ˆæ¯æ ¼å¼ä¸ºå‰ç«¯æ ¼å¼
        const formattedMessages = loadedMessages.map((msg: any) => ({
          id: msg.id || `msg-${Date.now()}-${Math.random()}`,
          role: msg.role,
          content: msg.isMultiAI && Array.isArray(msg.content)
            ? msg.content.map((r: any) => ({
                agentId: r.agentId,
                agentName: r.agentName,
                content: r.content || "",
                model: r.model,
                tokens: r.tokens || 0,
                cost: r.cost || 0,
                status: "completed" as const,
                timestamp: new Date(r.timestamp),
              }))
            : msg.content,
          isMultiAI: msg.isMultiAI || false,
          timestamp: new Date(msg.timestamp),
        }));

        // å¦‚æœæ•°æ®åº“æ¶ˆæ¯ä¸ºç©ºä¸”å½“å‰æ­£åœ¨å¤„ç†ï¼Œè¯´æ˜æ˜¯æ–°ä¼šè¯åˆšå¼€å§‹
        // ä¸è¦ç”¨ç©ºæ•°ç»„è¦†ç›–æœ¬åœ°çš„æ¶ˆæ¯ï¼Œé˜²æ­¢"AIå·²å°±ç»ª"ç•Œé¢é—ªç°
        if (formattedMessages.length === 0 && isProcessing) {
          console.log("[GPTWorkspace] Skipping empty message load during active processing");
          // åªåŠ è½½ä¼šè¯é…ç½®ï¼Œä¸æ›´æ–°æ¶ˆæ¯åˆ—è¡¨
          if (loadedSessionConfig) {
            setSessionConfig(loadedSessionConfig);
          }
          return;
        }

        // ç›´æ¥è®¾ç½®æ•°æ®åº“æ¶ˆæ¯ï¼ˆåˆ‡æ¢ä¼šè¯æ—¶æ›¿æ¢æœ¬åœ°æ¶ˆæ¯ï¼‰
        setMessages(formattedMessages);

        // åŠ è½½ä¼šè¯é…ç½®ï¼ˆç”¨äºæ˜¾ç¤ºAIé”å®šçŠ¶æ€ï¼‰
        if (loadedSessionConfig) {
          setSessionConfig(loadedSessionConfig);
          console.log("[GPTWorkspace] Loaded session config:", loadedSessionConfig);

          // å¦‚æœæ˜¯å¤šAIä¼šè¯ï¼Œæ¢å¤ä¹‹å‰é€‰æ‹©çš„AI
          if (loadedSessionConfig.isMultiAI && loadedSessionConfig.selectedAgentIds) {
            const restoredAIs = loadedSessionConfig.selectedAgentIds
              .map((agentId: string) =>
                availableAIs.find((ai) => ai.id === agentId)
              )
              .filter((ai: any) => ai !== undefined);

            if (restoredAIs.length > 0) {
              setSelectedGPTs(restoredAIs);
              console.log("[GPTWorkspace] Restored selected AIs:", restoredAIs);
            }
          }
        } else {
          setSessionConfig(null);
        }

        console.log(
          "[GPTWorkspace] Loaded",
          formattedMessages.length,
          "messages from database"
        );
      } catch (error) {
        console.error("[GPTWorkspace] Failed to load messages from database:", error);
      }
    };

    loadMessagesFromDatabase();
  }, [currentSessionId, availableAIs]);

  const handleSend = async () => {
    if (!input.trim() || isProcessing) return;

    if (selectedGPTs.length === 0) {
      toast.error(t.workspace.selectAI);
      return;
    }

    const userMessage: Message = {
      id: `user-${Date.now()}`,
      role: "user",
      content: input.trim(),
      timestamp: new Date(),
    };

    addMessage(userMessage);
    setInput("");
    setIsProcessing(true);
    setError(null);

    // åˆå§‹åŒ–AIå“åº”çŠ¶æ€
    const initialResponses: AIResponse[] = selectedGPTs.map((gpt) => ({
      agentId: gpt.id,
      agentName: gpt.name,
      content: "",
      status: "pending",
      timestamp: new Date(),
    }));
    setAIResponses(initialResponses);

    try {
      // è·å–è®¤è¯ Tokenï¼ˆæ”¯æŒ CloudBase å’Œ Supabaseï¼‰
      const { token: authToken, error: authError } = await getClientAuthToken();

      if (authError || !authToken) {
        toast.error("è¯·å…ˆç™»å½•", {
          description: "æ‚¨éœ€è¦ç™»å½•åæ‰èƒ½ä½¿ç”¨ AI å¯¹è¯åŠŸèƒ½",
        });
        setIsProcessing(false);
        return;
      }

      // å¦‚æœæ²¡æœ‰sessionIdï¼Œå…ˆåˆ›å»ºä¼šè¯
      let sessId = currentSessionId;
      if (!sessId) {
        sessId = await createSession(authToken, userMessage.content as string);
        setCurrentSessionId(sessId);
      }

      // å¹¶è¡Œæ¨¡å¼ï¼šå¤šä¸ªAIåŒæ—¶å¤„ç†
      const finalResponses = await handleParallelMode(
        sessId,
        authToken,
        userMessage.content as string,
        initialResponses
      );

      // ä¿å­˜å¤šAIå“åº”ä¸ºä¸€æ¡æ¶ˆæ¯
      const finalMessage: Message = {
        id: `ai-${Date.now()}`,
        role: "assistant",
        content: finalResponses,
        isMultiAI: true,
        timestamp: new Date(),
      };
      console.log("[GPTWorkspace] Adding final message:", finalMessage);
      console.log("[GPTWorkspace] Final responses:", finalResponses);

      // å…ˆæ¸…é™¤åä½œçŠ¶æ€ï¼Œé¿å…é—ªçƒ
      setIsProcessing(false);
      setAIResponses([]);

      // ç„¶åæ·»åŠ æœ€ç»ˆæ¶ˆæ¯
      addMessage(finalMessage);

      // ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ˆç»Ÿä¸€ä½¿ç”¨å¤šAIä¿å­˜APIï¼‰
      if (sessId) {
        try {
          const saveResponse = await fetch("/api/chat/save-multi-ai", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${authToken}`,
            },
            body: JSON.stringify({
              sessionId: sessId,
              userMessage: userMessage.content,
              aiResponses: finalResponses.map(r => ({
                agentId: r.agentId,
                agentName: r.agentName,
                content: r.content,
                model: selectedGPTs.find(g => g.id === r.agentId)?.model || "",
                status: r.status,
                timestamp: r.timestamp,
              })),
            }),
          });

          if (!saveResponse.ok) {
            console.error("[GPTWorkspace] Failed to save multi-AI message");
          }
        } catch (error) {
          console.error("[GPTWorkspace] Error saving multi-AI message:", error);
        }
      }
    } catch (error) {
      console.error("Multi-AI collaboration error:", error);
      setError(error instanceof Error ? error.message : t.workspace.error);
      toast.error(error instanceof Error ? error.message : t.workspace.error);
    } finally {
      // ç¡®ä¿çŠ¶æ€ä¸€å®šä¼šè¢«æ¸…é™¤
      setIsProcessing(false);
      setAIResponses([]);
    }
  };

  // å¹¶è¡Œæ¨¡å¼å¤„ç†ï¼ˆçœŸå® API è°ƒç”¨ï¼‰
  const handleParallelMode = async (
    sessionId: string,
    token: string,
    userMessage: string,
    responses: AIResponse[]
  ): Promise<AIResponse[]> => {
    const promises = selectedGPTs.map(async (gpt) => {
      try {
        // æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        setAIResponses((prev) =>
          prev.map((r) =>
            r.agentId === gpt.id ? { ...r, status: "processing" as const } : r
          )
        );

        // è°ƒç”¨çœŸå® API
        console.log(`[Frontend] Sending request for model: ${gpt.model}`);
        const response = await fetch("/api/chat/send", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${token}`,
          },
          body: JSON.stringify({
            sessionId,
            message: userMessage,
            model: gpt.model || "deepseek-chat",
            temperature: gpt.temperature || 0.7,
            maxTokens: gpt.maxTokens || 2048,
            agentName: gpt.name,
            agentId: gpt.id,
            skipSave: true, // ç»Ÿä¸€ç”±å‰ç«¯save-multi-aiä¿å­˜
          }),
        });

        console.log(
          `[Frontend] Response status: ${response.status} ${response.statusText}`
        );

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`[Frontend] Error response:`, errorText);
          throw new Error(`API Error: ${response.statusText}`);
        }

        // å¤„ç† SSE æµå¼å“åº”
        const reader = response.body?.getReader();
        const decoder = new TextDecoder();
        let accumulatedContent = "";
        let totalTokens = 0;
        let cost = 0;

        if (reader) {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            const chunk = decoder.decode(value);
            const lines = chunk.split("\n");

            for (const line of lines) {
              if (line.startsWith("data: ")) {
                try {
                  const data = JSON.parse(line.slice(6));

                  if (data.type === "content") {
                    accumulatedContent += data.content;

                    // å®æ—¶æ›´æ–°ç•Œé¢æ˜¾ç¤º
                    setAIResponses((prev) =>
                      prev.map((r) =>
                        r.agentId === gpt.id
                          ? {
                              ...r,
                              content: accumulatedContent,
                              status: "processing" as const,
                            }
                          : r
                      )
                    );
                  } else if (data.type === "done") {
                    totalTokens = data.tokens?.total || 0;
                    cost = data.cost || 0;
                  }
                } catch (e) {
                  // å¿½ç•¥è§£æé”™è¯¯
                }
              }
            }
          }
        }

        // å¦‚æœæ²¡æœ‰æ”¶åˆ° tokens ä¿¡æ¯ï¼Œä½¿ç”¨ä¼°ç®—å€¼
        if (!totalTokens && accumulatedContent) {
          totalTokens = Math.floor(accumulatedContent.length / 4);
        }

        // æ ‡è®°ä¸ºå®Œæˆ
        setAIResponses((prev) =>
          prev.map((r) =>
            r.agentId === gpt.id
              ? {
                  ...r,
                  content: accumulatedContent,
                  tokens: totalTokens,
                  cost: cost,
                  status: "completed" as const,
                }
              : r
          )
        );

        // è¿”å›å®Œæˆçš„å“åº”
        return {
          agentId: gpt.id,
          agentName: gpt.name,
          content: accumulatedContent,
          tokens: totalTokens,
          cost: cost,
          status: "completed" as const,
          timestamp: new Date(),
        } as AIResponse;
      } catch (error) {
        console.error(`AI ${gpt.name} error:`, error);
        setAIResponses((prev) =>
          prev.map((r) =>
            r.agentId === gpt.id
              ? { ...r, status: "error" as const, content: `Error: ${error}` }
              : r
          )
        );
        return {
          agentId: gpt.id,
          agentName: gpt.name,
          content: `Error: ${error}`,
          status: "error" as const,
          timestamp: new Date(),
        } as AIResponse;
      }
    });

    const results = await Promise.all(promises);

    // è¿”å›æœ€ç»ˆçš„å“åº”çŠ¶æ€
    console.log("[handleParallelMode] Returning results:", results);
    return results;
  };


  const createSession = async (token: string, firstMessage: string): Promise<string> => {
    try {
      // ä½¿ç”¨ç”¨æˆ·ç¬¬ä¸€æ¡æ¶ˆæ¯ä½œä¸ºæ ‡é¢˜,æœ€å¤š10ä¸ªå­—ç¬¦
      const title = firstMessage.length > 10
        ? firstMessage.substring(0, 10) + "..."
        : firstMessage;

      // åˆ¤æ–­æ˜¯å¦ä¸ºå¤šAIæ¨¡å¼
      const isMultiAI = selectedGPTs.length > 1;

      const sessionData: any = {
        title: title,
        model: selectedGPTs[0]?.model || "gpt-3.5-turbo",
      };

      // å¦‚æœæ˜¯å¤šAIæ¨¡å¼ï¼Œæ·»åŠ é…ç½®å‚æ•°
      if (isMultiAI) {
        sessionData.isMultiAI = true;
        sessionData.selectedAgentIds = selectedGPTs.map(gpt => gpt.id);
        sessionData.collaborationMode = "parallel";
        console.log("[GPTWorkspace] Creating multi-AI session with agents:", sessionData.selectedAgentIds);
      }

      const response = await fetch("/api/chat/sessions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${token}`,
        },
        body: JSON.stringify(sessionData),
      });

      if (!response.ok) {
        throw new Error(`Failed to create session: ${response.status}`);
      }

      const data = await response.json();
      console.log(`Session created:`, data.session);
      setSessionConfig(data.session.multi_ai_config || null);
      return data.session.id;
    } catch (error) {
      console.error("Failed to create session:", error);
      toast.error("åˆ›å»ºä¼šè¯å¤±è´¥", {
        description: "è¯·ç¨åé‡è¯•",
      });
      throw error;
    }
  };

  const getStatusColor = (status: string) => {
    switch (status) {
      case "processing":
        return "bg-blue-500";
      case "completed":
        return "bg-green-500";
      case "error":
        return "bg-red-500";
      default:
        return "bg-gray-300";
    }
  };

  const clearConversation = () => {
    setMessages([]);
    setCurrentSessionId(undefined);
    setSessionConfig(null);
    setAIResponses([]);
    setIsProcessing(false);
    setError(null);
    setInput("");
    console.log("ğŸ—‘ï¸ å·²æ¸…ç©ºå¯¹è¯");
  };

  const getStatusIcon = (status: string) => {
    switch (status) {
      case "processing":
        return <Loader2 className="w-3 h-3 text-white animate-spin" />;
      case "completed":
        return <CheckCircle2 className="w-3 h-3 text-white" />;
      case "error":
        return <AlertCircle className="w-3 h-3 text-white" />;
      default:
        return <Clock className="w-3 h-3 text-white" />;
    }
  };

  return (
    <div className="flex-1 flex flex-col h-full">
      {/* èŠå¤©åŒºåŸŸ */}
      <div
        ref={chatContainerRef}
        onScroll={handleChatScroll}
        className="flex-1 overflow-y-auto p-2 sm:p-4 lg:p-6 space-y-4 min-h-0">
        {messages.length === 0 && selectedGPTs.length === 0 && (
          <div className="text-center py-12">
            <Users className="w-16 h-16 text-blue-500 mx-auto mb-4" />
            <h3 className="text-lg font-semibold text-gray-900 mb-2">
              {t.workspace.welcome}
            </h3>
            <p className="text-sm text-gray-500 mb-6">{t.workspace.selectAI}</p>
          </div>
        )}

        {messages.length === 0 && selectedGPTs.length > 0 && !isProcessing && (
          <div className="text-center py-12">
            <Bot className="w-16 h-16 text-blue-500 mx-auto mb-4" />
            <h3 className="text-lg font-semibold text-gray-900 mb-2">
              {selectedGPTs.length} AI {t.workspace.aiReady}
            </h3>
            <p className="text-sm text-gray-500 mb-2">
              {t.workspace.parallel}
            </p>
            <p className="text-sm text-gray-500 mb-6">{t.workspace.example}</p>

            {/* æ˜¾ç¤ºå·²é€‰AI */}
            <div className="flex flex-wrap justify-center gap-2 max-w-2xl mx-auto">
              {selectedGPTs.map((gpt) => (
                <Badge key={gpt.id} variant="secondary" className="px-3 py-1">
                  {gpt.name}
                </Badge>
              ))}
            </div>
          </div>
        )}

        {messages.map((message) => (
          <div key={message.id}>
            {message.role === "user" ? (
              // ç”¨æˆ·æ¶ˆæ¯
              <div className="flex items-start gap-2 sm:gap-3 justify-end">
                <div className="inline-block max-w-xs sm:max-w-2xl lg:max-w-3xl">
                  <Card className="inline-block p-3 sm:p-4 bg-blue-500 text-white">
                    <p className="text-sm whitespace-pre-wrap break-words">
                      {typeof message.content === "string" ? message.content : ""}
                    </p>
                  </Card>
                </div>
                <div className="w-8 h-8 bg-blue-500 rounded-full flex items-center justify-center flex-shrink-0">
                  <User className="w-5 h-5 text-white" />
                </div>
              </div>
            ) : message.isMultiAI && Array.isArray(message.content) ? (
              // å¤šAIå“åº”
              <div className="space-y-3">
                {(message.content as AIResponse[]).length > 1 && (
                  <div className="flex items-center space-x-2 mb-2">
                    <Users className="w-5 h-5 text-blue-600" />
                    <h4 className="font-semibold text-blue-900">
                      {t.workspace.collaboration} (
                      {(message.content as AIResponse[]).length} AI)
                    </h4>
                  </div>
                )}

                {(message.content as AIResponse[]).map((aiResp) => (
                  <div
                    key={aiResp.agentId}
                    className="flex items-start space-x-3"
                  >
                    <div
                      className={`w-8 h-8 rounded-full flex items-center justify-center flex-shrink-0 ${getStatusColor(
                        aiResp.status
                      )}`}
                    >
                      {getStatusIcon(aiResp.status)}
                    </div>

                    <div className="flex-1 max-w-xs sm:max-w-2xl lg:max-w-3xl">
                      <div className="flex items-center space-x-2 mb-2">
                        <span className="font-medium text-sm">
                          {aiResp.agentName}
                        </span>
                        <Badge variant="outline" className="text-xs">
                          {aiResp.status === "completed"
                            ? t.workspace.completed
                            : aiResp.status === "processing"
                            ? t.workspace.processing_status
                            : aiResp.status === "error"
                            ? t.workspace.error
                            : t.workspace.pending}
                        </Badge>
                      </div>

                      <Card className="p-3 sm:p-4 bg-white border-gray-200 max-w-full">
                        {aiResp.content ? (
                          <MarkdownRenderer content={aiResp.content} />
                        ) : (
                          <p className="text-sm text-gray-500">{t.workspace.pending}</p>
                        )}
                      </Card>
                    </div>

                  </div>
                ))}
              </div>
            ) : message.role === "assistant" ? (
              // å•ä¸ªAIå“åº”ï¼ˆå†å²æ¶ˆæ¯ï¼‰
              <div className="flex items-start space-x-3">
                <div className="w-8 h-8 rounded-full flex items-center justify-center flex-shrink-0 bg-green-500">
                  {getStatusIcon("completed")}
                </div>

                <div className="inline-block max-w-xs sm:max-w-2xl lg:max-w-3xl">
                  <div className="flex items-center space-x-2 mb-2">
                    <span className="font-medium text-sm">
                      {(message as any).agentName ||
                       availableAIs.find(ai => ai.model === (message as any).model)?.name ||
                       (message as any).model ||
                       "AI Assistant"}
                    </span>
                    <Badge variant="outline" className="text-xs">
                      {t.workspace.completed}
                    </Badge>
                  </div>

                  <Card className="p-3 sm:p-4 bg-white border-gray-200 max-w-full">
                    {typeof message.content === "string" && message.content ? (
                      <MarkdownRenderer content={message.content} />
                    ) : (
                      <p className="text-sm text-gray-500">No content</p>
                    )}
                  </Card>
                </div>
              </div>
            ) : null}
          </div>
        ))}

        {/* å®æ—¶åä½œçŠ¶æ€æ˜¾ç¤º */}
        {isProcessing && aiResponses.length > 0 && (
          <Card className="p-4 bg-gradient-to-r from-blue-50 to-purple-50 border-blue-200">
            <div className="flex items-center justify-between mb-4">
              <div className="flex items-center space-x-2">
                <Users className="w-5 h-5 text-blue-600" />
                <h3 className="font-semibold text-blue-900">
                  {t.workspace.collaboration}
                </h3>
              </div>
              <Badge
                variant="secondary"
                className="bg-blue-100 text-blue-800 animate-pulse"
              >
                {t.workspace.processing}
              </Badge>
            </div>

            <div className="space-y-3">
              {aiResponses.map((aiResp) => (
                <div
                  key={aiResp.agentId}
                  className="flex items-start space-x-3"
                >
                  <div
                    className={`w-8 h-8 rounded-full flex items-center justify-center flex-shrink-0 ${getStatusColor(
                      aiResp.status
                    )}`}
                  >
                    {getStatusIcon(aiResp.status)}
                  </div>

                  <div className="flex-1 max-w-xs sm:max-w-2xl lg:max-w-3xl">
                    <div className="flex items-center space-x-2 mb-2">
                      <span className="font-medium text-sm">
                        {aiResp.agentName}
                      </span>
                      <Badge variant="outline" className="text-xs">
                        {aiResp.status === "completed"
                          ? t.workspace.completed
                          : aiResp.status === "processing"
                          ? t.workspace.processing_status
                          : t.workspace.pending}
                      </Badge>
                    </div>

                    {/* æ˜¾ç¤ºå®æ—¶ç”Ÿæˆçš„å†…å®¹ */}
                    {aiResp.content && (
                      <Card className="p-3 bg-white border-gray-200 max-w-full">
                        <div>
                          <MarkdownRenderer content={aiResp.content} />
                          {aiResp.status === "processing" && (
                            <span className="inline-block w-2 h-4 ml-1 bg-blue-500 animate-pulse" />
                          )}
                        </div>
                      </Card>
                    )}
                  </div>

                </div>
              ))}
            </div>
          </Card>
        )}

        {/* é”™è¯¯æç¤º */}
        {error && (
          <Card className="p-4 bg-red-50 border-red-200">
            <div className="flex items-start space-x-2">
              <AlertCircle className="w-5 h-5 text-red-600 flex-shrink-0 mt-0.5" />
              <div className="flex-1">
                <p className="text-sm text-red-800">{error}</p>
                <Button
                  variant="outline"
                  size="sm"
                  onClick={() => setError(null)}
                  className="mt-2"
                >
                  {t.workspace.retry}
                </Button>
              </div>
            </div>
          </Card>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* å·¥å…·æ  */}
      <ChatToolbar
        selectedAIs={selectedGPTs}
        onAIsChange={setSelectedGPTs}
        availableAIs={availableAIs}
        sessionId={currentSessionId}
        sessionConfig={sessionConfig}
      />

      {/* è¾“å…¥åŒºåŸŸ */}
      <div className="p-2 sm:p-4 bg-white">
        <div className="flex gap-2 sm:gap-3">
          <Textarea
            value={input}
            onChange={(e) => setInput(e.target.value)}
            placeholder={t.workspace.placeholder}
            className="flex-1 min-h-[80px] sm:min-h-[80px] max-h-[200px] resize-none text-sm sm:text-base"
            onKeyDown={(e) => {
              if (e.key === "Enter" && !e.shiftKey) {
                e.preventDefault();
                handleSend();
              }
            }}
            disabled={isProcessing || selectedGPTs.length === 0}
          />
          <Button
            onClick={handleSend}
            disabled={
              !input.trim() || isProcessing || selectedGPTs.length === 0
            }
            className="px-4 sm:px-6 h-[80px] self-end"
          >
            {isProcessing ? (
              <Loader2 className="w-4 h-4 animate-spin" />
            ) : (
              <Send className="w-4 h-4" />
            )}
          </Button>
        </div>
      </div>
    </div>
  );
}
