# AIé…ç½®æŒ‡å— - å¦‚ä½•æ·»åŠ æ–°çš„AIæ™ºèƒ½ä½“

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•åœ¨ç³»ç»Ÿä¸­æ·»åŠ å’Œé…ç½®æ–°çš„AIæ™ºèƒ½ä½“ã€‚

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿæ·»åŠ æ–°AI](#å¿«é€Ÿæ·»åŠ æ–°ai)
- [é…ç½®æ–‡ä»¶è¯¦è§£](#é…ç½®æ–‡ä»¶è¯¦è§£)
- [æ·»åŠ æ–°Provider](#æ·»åŠ æ–°provider)
- [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)
- [æµ‹è¯•å’Œè°ƒè¯•](#æµ‹è¯•å’Œè°ƒè¯•)

---

## ğŸš€ å¿«é€Ÿæ·»åŠ æ–°AI

### æ–¹æ³•1: ä½¿ç”¨ç°æœ‰Providerï¼ˆæ¨èï¼‰

å¦‚æœä½ è¦æ·»åŠ çš„AIæ¨¡å‹ä½¿ç”¨å·²æ”¯æŒçš„Providerï¼ˆOpenAIã€Anthropicç­‰ï¼‰ï¼Œåªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ï¼š

**æ–‡ä»¶**: `lib/ai/ai-agents.config.ts`

```typescript
{
  id: 'my-new-ai',               // å”¯ä¸€ID
  name: 'æˆ‘çš„æ–°AI',               // æ˜¾ç¤ºåç§°
  provider: 'openai',            // ä½¿ç”¨ç°æœ‰provider
  model: 'gpt-4',                // æ¨¡å‹åç§°
  role: 'ä¸“ä¸šè§’è‰²',               // è§’è‰²æè¿°
  color: 'bg-blue-500',          // Tailwindé¢œè‰²ç±»
  systemPrompt: 'ä½ æ˜¯...',       // ç³»ç»Ÿæç¤ºè¯
  temperature: 0.7,              // æ¸©åº¦å‚æ•°
  capabilities: {                // èƒ½åŠ›æ ‡ç­¾
    coding: true,
    analysis: true,
  },
  tags: ['æ ‡ç­¾1', 'æ ‡ç­¾2'],       // åˆ†ç±»æ ‡ç­¾
  description: 'è¿™ä¸ªAIçš„ç”¨é€”',    // æè¿°
  enabled: true,                 // å¯ç”¨çŠ¶æ€
  order: 50,                     // æ˜¾ç¤ºé¡ºåº
}
```

### æ–¹æ³•2: æ·»åŠ å…¨æ–°çš„Provider

å¦‚æœéœ€è¦é›†æˆæ–°çš„AIæœåŠ¡å•†ï¼š

1. **åˆ›å»ºProviderå®ç°**

**æ–‡ä»¶**: `lib/ai/providers/my-provider.ts`

```typescript
import { BaseAIProvider } from './base-provider';
import { AIMessage, AIResponse, StreamChunk, ChatOptions, ModelInfo } from '../types';

export class MyProvider extends BaseAIProvider {
  readonly name = 'myprovider';
  readonly models = ['model-1', 'model-2'];
  readonly defaultModel = 'model-1';

  constructor() {
    super();
    // åˆå§‹åŒ–ä½ çš„APIå®¢æˆ·ç«¯
  }

  getModelInfo(model: string): ModelInfo | null {
    // è¿”å›æ¨¡å‹ä¿¡æ¯
    return {
      id: model,
      name: 'My Model',
      provider: this.name,
      contextWindow: 4096,
      pricing: { prompt: 0.001, completion: 0.002 },
      capabilities: {
        streaming: true,
        functionCalling: false,
        vision: false,
      },
    };
  }

  async chat(messages: AIMessage[], options?: ChatOptions): Promise<AIResponse> {
    // å®ç°éæµå¼è°ƒç”¨
    try {
      this.validateMessages(messages);
      const model = this.getValidModel(options?.model);

      // è°ƒç”¨ä½ çš„API
      const result = await yourApiClient.chat({
        messages,
        model,
        temperature: options?.temperature,
      });

      return {
        content: result.content,
        tokens: {
          prompt: result.promptTokens,
          completion: result.completionTokens,
          total: result.totalTokens,
        },
        model: result.model,
        finish_reason: result.finishReason,
      };
    } catch (error) {
      throw this.handleError(error);
    }
  }

  async *chatStream(messages: AIMessage[], options?: ChatOptions): AsyncIterableIterator<StreamChunk> {
    // å®ç°æµå¼è°ƒç”¨
    this.validateMessages(messages);
    const model = this.getValidModel(options?.model);

    const stream = await yourApiClient.chatStream({
      messages,
      model,
    });

    for await (const chunk of stream) {
      yield {
        content: chunk.content,
        done: chunk.isDone,
        tokens: chunk.tokens,
      };
    }
  }

  countTokens(messages: AIMessage[], model?: string): number {
    // å®ç°Tokenè®¡æ•°
    return messages.reduce((sum, msg) => sum + Math.ceil(msg.content.length / 4), 0);
  }
}
```

2. **æ³¨å†ŒProvider**

**æ–‡ä»¶**: `lib/ai/router.ts`

```typescript
import { MyProvider } from './providers/my-provider';

class AIRouter {
  private constructor() {
    this.initialize();
  }

  private initialize(): void {
    // ... existing providers ...

    // æ·»åŠ ä½ çš„provider
    if (process.env.MY_PROVIDER_API_KEY) {
      const myProvider = new MyProvider();
      this.registerProvider(myProvider);
    }
  }
}
```

3. **æ·»åŠ ç¯å¢ƒå˜é‡**

**æ–‡ä»¶**: `.env.local`

```bash
MY_PROVIDER_API_KEY=your-api-key-here
```

4. **åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ AI**

**æ–‡ä»¶**: `lib/ai/ai-agents.config.ts`

```typescript
{
  id: 'my-custom-ai',
  name: 'æˆ‘çš„è‡ªå®šä¹‰AI',
  provider: 'myprovider',  // ä½ çš„provideråç§°
  model: 'model-1',
  role: 'ä¸“å®¶',
  color: 'bg-purple-500',
  systemPrompt: 'ä½ æ˜¯ä¸€ä¸ª...',
  temperature: 0.7,
  capabilities: { coding: true },
  tags: ['è‡ªå®šä¹‰'],
  description: 'è¿™æ˜¯æˆ‘æ·»åŠ çš„AI',
  enabled: true,
}
```

---

## ğŸ“– é…ç½®æ–‡ä»¶è¯¦è§£

### AIAgentConfig æ¥å£

```typescript
interface AIAgentConfig {
  // å¿…å¡«å­—æ®µ
  id: string                  // å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå…¨å±€å”¯ä¸€
  name: string                // æ˜¾ç¤ºåç§°ï¼ˆä¸­æ–‡ï¼‰
  provider: string            // Provideråç§°: openai, anthropicç­‰
  model: string               // æ¨¡å‹ID
  role: string                // è§’è‰²æè¿°
  color: string               // Tailwindé¢œè‰²ç±»ï¼ˆå¦‚ bg-blue-500ï¼‰
  systemPrompt: string        // ç³»ç»Ÿæç¤ºè¯
  capabilities: {             // AIçš„èƒ½åŠ›æ ‡ç­¾
    coding?: boolean
    analysis?: boolean
    creative?: boolean
    research?: boolean
    translation?: boolean
    math?: boolean
    [key: string]: boolean | undefined
  }
  tags: string[]              // åˆ†ç±»æ ‡ç­¾æ•°ç»„
  description: string         // è¯¦ç»†æè¿°
  enabled: boolean            // æ˜¯å¦å¯ç”¨

  // å¯é€‰å­—æ®µ
  nameEn?: string             // è‹±æ–‡åç§°
  roleEn?: string             // è‹±æ–‡è§’è‰²
  avatar?: string             // å¤´åƒURL
  temperature?: number        // æ¸©åº¦ (0-2)ï¼Œé»˜è®¤0.7
  maxTokens?: number          // æœ€å¤§tokenæ•°
  topP?: number               // Top-pé‡‡æ ·
  descriptionEn?: string      // è‹±æ–‡æè¿°
  isPremium?: boolean         // æ˜¯å¦éœ€è¦ä»˜è´¹è®¢é˜…
  order?: number              // æ˜¾ç¤ºé¡ºåº
}
```

### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| `id` | string | å…¨å±€å”¯ä¸€æ ‡è¯†ç¬¦ | `'gpt-4-turbo'` |
| `name` | string | æ˜¾ç¤ºåœ¨UIçš„åç§° | `'GPT-4 Turbo'` |
| `provider` | string | Provideræ ‡è¯† | `'openai'` |
| `model` | string | å®é™…çš„æ¨¡å‹ID | `'gpt-4-turbo'` |
| `role` | string | è§’è‰²å®šä½ | `'æˆ˜ç•¥åˆ†æå¸ˆ'` |
| `color` | string | TailwindèƒŒæ™¯è‰²ç±» | `'bg-purple-500'` |
| `systemPrompt` | string | å®šä¹‰AIè¡Œä¸ºçš„æç¤ºè¯ | `'ä½ æ˜¯ä¸€ä½...'` |
| `temperature` | number | åˆ›é€ æ€§ç¨‹åº¦(0-2) | `0.7` |
| `capabilities` | object | èƒ½åŠ›æ ‡ç­¾ | `{ coding: true }` |
| `tags` | string[] | ç”¨äºæœç´¢å’Œåˆ†ç±» | `['ç¼–ç¨‹', 'æŠ€æœ¯']` |
| `enabled` | boolean | æ˜¯å¦åœ¨ç³»ç»Ÿä¸­å¯ç”¨ | `true` |
| `isPremium` | boolean | æ˜¯å¦éœ€è¦ä»˜è´¹ | `false` |
| `order` | number | æ˜¾ç¤ºæ’åº | `10` |

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å‘½åè§„èŒƒ

```typescript
// âœ… æ¨è
id: 'gpt-4-turbo'           // å°å†™ï¼Œç”¨è¿å­—ç¬¦
name: 'GPT-4 Turbo'         // é¦–å­—æ¯å¤§å†™
role: 'æˆ˜ç•¥åˆ†æå¸ˆ'           // ç®€æ´æ˜ç¡®

// âŒ ä¸æ¨è
id: 'GPT4Turbo'             // ä¸è¦ç”¨é©¼å³°
name: 'gpt4turbo'           // ä¸è¦å…¨å°å†™
role: 'è¿™æ˜¯ä¸€ä¸ªå¾ˆå‰å®³çš„AI'   // å¤ªå†—é•¿
```

### 2. SystemPrompt ç¼–å†™

```typescript
// âœ… æ¨è - ç»“æ„åŒ–ã€æ¸…æ™°
systemPrompt: `ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶å·¥ç¨‹å¸ˆã€‚ä½ çš„å›ç­”åº”è¯¥ï¼š
1. æä¾›æ¸…æ™°çš„ä»£ç ç¤ºä¾‹
2. è§£é‡Šå…³é”®æ¦‚å¿µ
3. è€ƒè™‘æœ€ä½³å®è·µ
4. åŒ…å«å¿…è¦çš„æ³¨é‡Š`

// âŒ ä¸æ¨è - æ¨¡ç³Šã€æ³›æ³›
systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·å¸®åŠ©ç”¨æˆ·'
```

### 3. Temperature è®¾ç½®

```typescript
// ä»£ç ç”Ÿæˆ - ä½æ¸©åº¦ï¼ˆæ›´ç²¾ç¡®ï¼‰
temperature: 0.3

// é€šç”¨å¯¹è¯ - ä¸­ç­‰æ¸©åº¦
temperature: 0.7

// åˆ›æ„å†™ä½œ - é«˜æ¸©åº¦ï¼ˆæ›´å‘æ•£ï¼‰
temperature: 0.9
```

### 4. èƒ½åŠ›æ ‡ç­¾

```typescript
// âœ… å‡†ç¡®æ ‡æ³¨
capabilities: {
  coding: true,      // ç¡®å®æ“…é•¿ç¼–ç¨‹
  analysis: true,    // ç¡®å®æ“…é•¿åˆ†æ
}

// âŒ é¿å…è¿‡åº¦æ ‡æ³¨
capabilities: {
  coding: true,
  analysis: true,
  creative: true,
  research: true,
  translation: true,
  math: true,
  design: true,     // ä¸è¦æŠŠæ‰€æœ‰æ ‡ç­¾éƒ½æ ‡ä¸Š
}
```

---

## ğŸ”Œ æ·»åŠ æ–°Providerç¤ºä¾‹

### ç¤ºä¾‹ï¼šé›†æˆGemini

```typescript
// lib/ai/providers/gemini-provider.ts
import { GoogleGenerativeAI } from '@google/generative-ai';
import { BaseAIProvider } from './base-provider';

export class GeminiProvider extends BaseAIProvider {
  readonly name = 'gemini';
  readonly models = ['gemini-pro', 'gemini-pro-vision'];
  readonly defaultModel = 'gemini-pro';

  private client: GoogleGenerativeAI;

  constructor() {
    super();
    this.client = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
  }

  async chat(messages, options) {
    const model = this.client.getGenerativeModel({ model: options?.model || this.defaultModel });
    const result = await model.generateContent(messages[messages.length - 1].content);
    const response = await result.response;

    return {
      content: response.text(),
      tokens: { prompt: 0, completion: 0, total: 0 },
      model: options?.model || this.defaultModel,
      finish_reason: 'stop',
    };
  }

  // ... å…¶ä»–å¿…éœ€æ–¹æ³•
}
```

**é…ç½®**:

```typescript
// lib/ai/ai-agents.config.ts
{
  id: 'gemini-pro',
  name: 'Gemini Pro',
  provider: 'gemini',
  model: 'gemini-pro',
  role: 'Google AIåŠ©æ‰‹',
  color: 'bg-blue-600',
  systemPrompt: 'ä½ æ˜¯Google Gemini AI',
  capabilities: { coding: true, analysis: true },
  tags: ['Google', 'å¤šæ¨¡æ€'],
  description: 'Googleæœ€æ–°çš„å¤šæ¨¡æ€AI',
  enabled: true,
}
```

---

## ğŸ§ª æµ‹è¯•å’Œè°ƒè¯•

### 1. æµ‹è¯•å•ä¸ªAI

```typescript
import { getAgentById } from '@/lib/ai/ai-agents.config';
import { aiRouter } from '@/lib/ai/router';

// è·å–AIé…ç½®
const agent = getAgentById('my-new-ai');

// æµ‹è¯•è°ƒç”¨
const provider = aiRouter.getProviderForModel(agent.model);
const result = await provider.chat([
  { role: 'system', content: agent.systemPrompt },
  { role: 'user', content: 'æµ‹è¯•æ¶ˆæ¯' }
], {
  model: agent.model,
  temperature: agent.temperature,
});

console.log(result);
```

### 2. æµ‹è¯•å¤šAIåä½œ

```bash
curl -X POST http://localhost:3000/api/chat/multi-send \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "sessionId": "test-session",
    "message": "æµ‹è¯•æ¶ˆæ¯",
    "agentIds": ["gpt-3.5-turbo", "my-new-ai"],
    "mode": "parallel"
  }'
```

### 3. è°ƒè¯•æŠ€å·§

```typescript
// åœ¨providerä¸­æ·»åŠ æ—¥å¿—
console.log('[MyProvider] Request:', messages);
console.log('[MyProvider] Response:', result);
console.log('[MyProvider] Tokens:', result.tokens);

// åœ¨é…ç½®ä¸­ä¸´æ—¶ç¦ç”¨å…¶ä»–AI
const AI_AGENTS_LIBRARY = AI_AGENTS_LIBRARY.map(a =>
  a.id === 'my-new-ai' ? a : { ...a, enabled: false }
);
```

---

## ğŸ“š å®Œæ•´ç¤ºä¾‹

### æ·»åŠ ä¸€ä¸ª"æ•°å­¦ä¸“å®¶"AI

```typescript
// 1. åœ¨ lib/ai/ai-agents.config.ts ä¸­æ·»åŠ 
{
  id: 'math-expert',
  name: 'æ•°å­¦ä¸“å®¶',
  nameEn: 'Math Expert',
  provider: 'openai',
  model: 'gpt-4-turbo',
  role: 'æ•°å­¦æ•™æˆ',
  roleEn: 'Math Professor',
  color: 'bg-amber-600',
  systemPrompt: `ä½ æ˜¯ä¸€ä½æ•°å­¦æ•™æˆã€‚ä½ çš„å›ç­”åº”è¯¥ï¼š
1. ä½¿ç”¨LaTeXæ ¼å¼å±•ç¤ºæ•°å­¦å…¬å¼
2. é€æ­¥å±•ç¤ºæ±‚è§£è¿‡ç¨‹
3. è§£é‡Šæ¯ä¸€æ­¥çš„æ•°å­¦åŸç†
4. æä¾›ç›¸å…³çš„æ•°å­¦å®šç†å’Œå…¬å¼`,
  temperature: 0.3, // æ•°å­¦éœ€è¦ç²¾ç¡®
  maxTokens: 4096,
  capabilities: {
    math: true,
    analysis: true,
    research: true,
  },
  tags: ['æ•°å­¦', 'æ•™è‚²', 'ç†å·¥'],
  description: 'ä¸“æ³¨äºæ•°å­¦é—®é¢˜çš„æ±‚è§£ã€è¯æ˜å’Œæ•™å­¦',
  descriptionEn: 'Specialized in mathematical problem-solving, proofs, and teaching',
  enabled: true,
  isPremium: false,
  order: 30,
},
```

### ä½¿ç”¨ç¤ºä¾‹

```typescript
// å‰ç«¯è°ƒç”¨
const response = await fetch('/api/chat/multi-send', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${token}`,
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    sessionId: 'session-123',
    message: 'è¯æ˜å‹¾è‚¡å®šç†',
    agentIds: ['math-expert'],
    mode: 'parallel',
  }),
});
```

---

## ğŸ“ é«˜çº§æŠ€å·§

### åŠ¨æ€åŠ è½½AIé…ç½®

ä»æ•°æ®åº“åŠ è½½AIé…ç½®ï¼š

```typescript
// lib/ai/dynamic-agents.ts
export async function loadAgentsFromDatabase() {
  const { data } = await supabase.from('ai_agents').select('*').eq('enabled', true);
  return data.map(agent => ({
    ...agent,
    capabilities: JSON.parse(agent.capabilities),
    tags: JSON.parse(agent.tags),
  }));
}

// åœ¨routerä¸­ä½¿ç”¨
const dbAgents = await loadAgentsFromDatabase();
AI_AGENTS_LIBRARY.push(...dbAgents);
```

### æ¡ä»¶å¯ç”¨AI

æ ¹æ®ç”¨æˆ·åœ°åŒºå¯ç”¨ä¸åŒAIï¼š

```typescript
const chinaAgents = getAgentsByProvider('deepseek');
const internationalAgents = getAgentsByProvider('openai');

const availableAgents = isChina ? chinaAgents : internationalAgents;
```

---

## â“ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•ä¸´æ—¶ç¦ç”¨æŸä¸ªAIï¼Ÿ
A: å°†é…ç½®ä¸­çš„ `enabled` è®¾ä¸º `false`

### Q: å¦‚ä½•ä¿®æ”¹å·²æœ‰AIçš„æç¤ºè¯ï¼Ÿ
A: ç›´æ¥ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ `systemPrompt` å­—æ®µ

### Q: å¦‚ä½•æ·»åŠ ä»˜è´¹AIï¼Ÿ
A: è®¾ç½® `isPremium: true`ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æŸ¥ç”¨æˆ·è®¢é˜…

### Q: Tokenè®¡æ•°ä¸å‡†ç¡®æ€ä¹ˆåŠï¼Ÿ
A: å®ç°ç²¾ç¡®çš„ `countTokens` æ–¹æ³•ï¼Œæˆ–ä½¿ç”¨ tiktoken åº“

---

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹ç°æœ‰AIé…ç½®ç¤ºä¾‹
- å‚è€ƒ `BaseAIProvider` æ–‡æ¡£
- æµ‹è¯•APIç«¯ç‚¹ `/api/chat/multi-send`

---

**æç¤º**: æ¯æ¬¡ä¿®æ”¹é…ç½®åï¼Œé‡å¯å¼€å‘æœåŠ¡å™¨ä»¥åŠ è½½æ–°é…ç½®ã€‚
