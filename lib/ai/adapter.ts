/**
 * AI æœåŠ¡é€‚é…å™¨
 *
 * æ ¹æ® DEPLOY_REGION ç¯å¢ƒå˜é‡é€‰æ‹©ä½¿ç”¨å“ªä¸ª AI æœåŠ¡æä¾›å•†ï¼š
 * - CNï¼ˆä¸­å›½ï¼‰ï¼šä½¿ç”¨ DeepSeek API
 * - INTLï¼ˆå›½é™…ï¼‰ï¼šä½¿ç”¨ Vercel AI Gateway
 */

import { isChinaRegion, RegionConfig } from "@/lib/config/region";

/**
 * AI æ¶ˆæ¯æ¥å£
 */
export interface AIMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

/**
 * AI å“åº”æ¥å£
 */
export interface AIResponse {
  content: string;
  model: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

/**
 * AI æµå¼å“åº”æ¥å£
 */
export interface AIStreamResponse {
  stream: ReadableStream;
  model: string;
}

/**
 * AI é€‚é…å™¨æ¥å£
 */
export interface AIAdapter {
  /**
   * å‘é€èŠå¤©æ¶ˆæ¯ï¼ˆéæµå¼ï¼‰
   * @param messages æ¶ˆæ¯å†å²
   * @param model æ¨¡å‹åç§°
   * @returns AI å“åº”
   */
  chat(messages: AIMessage[], model?: string): Promise<AIResponse>;

  /**
   * å‘é€èŠå¤©æ¶ˆæ¯ï¼ˆæµå¼ï¼‰
   * @param messages æ¶ˆæ¯å†å²
   * @param model æ¨¡å‹åç§°
   * @returns æµå¼å“åº”
   */
  chatStream(messages: AIMessage[], model?: string): Promise<AIStreamResponse>;

  /**
   * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  getAvailableModels(): string[];

  /**
   * è·å–é»˜è®¤æ¨¡å‹
   */
  getDefaultModel(): string;
}

/**
 * Vercel AI Gateway é€‚é…å™¨ï¼ˆå›½é™…ç‰ˆï¼‰
 */
class VercelAIGatewayAdapter implements AIAdapter {
  private apiKey: string;
  private baseUrl: string = "https://gateway.ai.cloudflare.com/v1";

  constructor() {
    this.apiKey = process.env.AI_GATEWAY_API_KEY || "";
  }

  async chat(
    messages: AIMessage[],
    model: string = "openai/gpt-4o-mini"
  ): Promise<AIResponse> {
    const response = await fetch(
      "https://ai-gateway.vercel.sh/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model,
          messages: messages.map((msg) => ({
            role: msg.role,
            content: msg.content,
          })),
          stream: false,
        }),
      }
    );

    if (!response.ok) {
      throw new Error(`Vercel AI Gateway error: ${response.status}`);
    }

    const data = await response.json();

    return {
      content: data.choices[0]?.message?.content || "",
      model: data.model,
      usage: data.usage,
    };
  }

  async chatStream(
    messages: AIMessage[],
    model: string = "openai/gpt-4o-mini"
  ): Promise<AIStreamResponse> {
    const response = await fetch(
      "https://ai-gateway.vercel.sh/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model,
          messages: messages.map((msg) => ({
            role: msg.role,
            content: msg.content,
          })),
          stream: true,
        }),
      }
    );

    if (!response.ok) {
      throw new Error(`Vercel AI Gateway error: ${response.status}`);
    }

    if (!response.body) {
      throw new Error("å“åº”ä½“ä¸ºç©º");
    }

    return {
      stream: response.body,
      model,
    };
  }

  getAvailableModels(): string[] {
    return [
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "anthropic/claude-sonnet-4",
      "anthropic/claude-opus-4",
      "google/gemini-2.0-flash",
    ];
  }

  getDefaultModel(): string {
    return "openai/gpt-4o-mini";
  }
}

/**
 * DeepSeek é€‚é…å™¨ï¼ˆä¸­å›½ç‰ˆï¼‰
 */
class DeepSeekAdapter implements AIAdapter {
  private apiKey: string;
  private baseUrl: string;

  constructor() {
    this.apiKey = process.env.DEEPSEEK_API_KEY || "";
    this.baseUrl = process.env.DEEPSEEK_BASE_URL || "https://api.deepseek.com";
  }

  async chat(
    messages: AIMessage[],
    model: string = "deepseek-chat"
  ): Promise<AIResponse> {
    const response = await fetch(`${this.baseUrl}/v1/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages: messages.map((msg) => ({
          role: msg.role,
          content: msg.content,
        })),
        stream: false,
      }),
    });

    if (!response.ok) {
      throw new Error(`DeepSeek API error: ${response.status}`);
    }

    const data = await response.json();

    return {
      content: data.choices[0]?.message?.content || "",
      model: data.model,
      usage: data.usage,
    };
  }

  async chatStream(
    messages: AIMessage[],
    model: string = "deepseek-chat"
  ): Promise<AIStreamResponse> {
    const response = await fetch(`${this.baseUrl}/v1/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${this.apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages: messages.map((msg) => ({
          role: msg.role,
          content: msg.content,
        })),
        stream: true,
      }),
    });

    if (!response.ok) {
      throw new Error(`DeepSeek API error: ${response.status}`);
    }

    if (!response.body) {
      throw new Error("å“åº”ä½“ä¸ºç©º");
    }

    return {
      stream: response.body,
      model,
    };
  }

  getAvailableModels(): string[] {
    return ["deepseek-chat", "deepseek-coder"];
  }

  getDefaultModel(): string {
    return "deepseek-chat";
  }
}

/**
 * åˆ›å»º AI é€‚é…å™¨å®ä¾‹
 * æ ¹æ® DEPLOY_REGION ç¯å¢ƒå˜é‡è‡ªåŠ¨é€‰æ‹©
 */
export function createAIAdapter(): AIAdapter {
  if (isChinaRegion()) {
    console.log("ğŸ¤– ä½¿ç”¨ DeepSeek AIï¼ˆä¸­å›½ç‰ˆï¼‰");
    return new DeepSeekAdapter();
  } else {
    console.log("ğŸ¤– ä½¿ç”¨ Vercel AI Gatewayï¼ˆå›½é™…ç‰ˆï¼‰");
    return new VercelAIGatewayAdapter();
  }
}

/**
 * å…¨å±€ AI å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
 */
let aiInstance: AIAdapter | null = null;

/**
 * è·å– AI å®ä¾‹
 */
export function getAI(): AIAdapter {
  if (!aiInstance) {
    aiInstance = createAIAdapter();
  }
  return aiInstance;
}

/**
 * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
 */
export function getAvailableModels(): string[] {
  return RegionConfig.ai.availableModels;
}

/**
 * è·å–é»˜è®¤æ¨¡å‹
 */
export function getDefaultAIModel(): string {
  if (isChinaRegion()) {
    return "deepseek-chat";
  } else {
    return "openai/gpt-4o-mini";
  }
}

/**
 * æ ¼å¼åŒ–æ¨¡å‹åç§°æ˜¾ç¤º
 */
export function formatModelName(model: string): string {
  const modelMap: Record<string, string> = {
    "openai/gpt-4o": "GPT-4o",
    "openai/gpt-4o-mini": "GPT-4o Mini",
    "anthropic/claude-sonnet-4": "Claude Sonnet 4",
    "anthropic/claude-opus-4": "Claude Opus 4",
    "google/gemini-2.0-flash": "Gemini 2.0 Flash",
    "deepseek-chat": "DeepSeek Chat",
    "deepseek-coder": "DeepSeek Coder",
  };

  return modelMap[model] || model;
}
